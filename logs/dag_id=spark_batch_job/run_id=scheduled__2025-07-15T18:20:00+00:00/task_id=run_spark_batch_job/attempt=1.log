{"timestamp":"2025-07-15T18:21:19.543522","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-15T18:21:19.544960","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/spark_batch_job_dag.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-15T18:21:19.563187","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:19.563923","level":"info","event":"Running command: ['/usr/bin/bash', '-c', 'spark-submit --jars /tmp/postgresql-42.7.3.jar /opt/airflow/scripts/spark_jop/batch_jop.py']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:19.592824","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:19.931930","level":"info","event":"WARNING: Using incubator modules: jdk.incubator.vector","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:23.969405","level":"info","event":"25/07/15 18:21:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:26.977150","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:26.987951","level":"info","event":"25/07/15 18:21:26 INFO SparkContext: Running Spark version 4.0.0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:26.993832","level":"info","event":"25/07/15 18:21:26 INFO SparkContext: OS info Linux, 6.11.0-29-generic, amd64","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:26.994958","level":"info","event":"25/07/15 18:21:26 INFO SparkContext: Java version 17.0.15","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:27.044050","level":"info","event":"25/07/15 18:21:27 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:27.049189","level":"info","event":"25/07/15 18:21:27 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:27.049503","level":"info","event":"25/07/15 18:21:27 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:27.049742","level":"info","event":"25/07/15 18:21:27 INFO SparkContext: Submitted application: Batch Job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:27.107255","level":"info","event":"25/07/15 18:21:27 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:27.115244","level":"info","event":"25/07/15 18:21:27 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:27.119867","level":"info","event":"25/07/15 18:21:27 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:27.234662","level":"info","event":"25/07/15 18:21:27 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:27.236371","level":"info","event":"25/07/15 18:21:27 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:27.237398","level":"info","event":"25/07/15 18:21:27 INFO SecurityManager: Changing view acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:27.238437","level":"info","event":"25/07/15 18:21:27 INFO SecurityManager: Changing modify acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:27.243271","level":"info","event":"25/07/15 18:21:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:27.661802","level":"info","event":"25/07/15 18:21:27 INFO Utils: Successfully started service 'sparkDriver' on port 37901.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:27.736469","level":"info","event":"25/07/15 18:21:27 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:27.758250","level":"info","event":"25/07/15 18:21:27 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:27.791372","level":"info","event":"25/07/15 18:21:27 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:27.793698","level":"info","event":"25/07/15 18:21:27 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:27.800008","level":"info","event":"25/07/15 18:21:27 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:27.854682","level":"info","event":"25/07/15 18:21:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2ed2ce5f-3b72-4f00-a4f1-3903feb2f959","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:27.933101","level":"info","event":"25/07/15 18:21:27 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:28.236547","level":"info","event":"25/07/15 18:21:28 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:28.415319","level":"info","event":"25/07/15 18:21:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:28.432044","level":"info","event":"25/07/15 18:21:28 INFO Utils: Successfully started service 'SparkUI' on port 4041.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:28.524137","level":"info","event":"25/07/15 18:21:28 INFO SparkContext: Added JAR file:///tmp/postgresql-42.7.3.jar at spark://ee98e9136741:37901/jars/postgresql-42.7.3.jar with timestamp 1752603686958","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:28.578470","level":"info","event":"25/07/15 18:21:28 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:28.578919","level":"info","event":"25/07/15 18:21:28 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:28.579184","level":"info","event":"25/07/15 18:21:28 INFO SecurityManager: Changing view acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:28.581569","level":"info","event":"25/07/15 18:21:28 INFO SecurityManager: Changing modify acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:28.582220","level":"info","event":"25/07/15 18:21:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:28.840192","level":"info","event":"25/07/15 18:21:28 INFO Executor: Starting executor ID driver on host ee98e9136741","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:28.840576","level":"info","event":"25/07/15 18:21:28 INFO Executor: OS info Linux, 6.11.0-29-generic, amd64","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:28.842462","level":"info","event":"25/07/15 18:21:28 INFO Executor: Java version 17.0.15","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:28.874608","level":"info","event":"25/07/15 18:21:28 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:28.878068","level":"info","event":"25/07/15 18:21:28 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4d81d772 for default.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:28.907790","level":"info","event":"25/07/15 18:21:28 INFO Executor: Fetching spark://ee98e9136741:37901/jars/postgresql-42.7.3.jar with timestamp 1752603686958","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:29.049568","level":"info","event":"25/07/15 18:21:29 INFO TransportClientFactory: Successfully created connection to ee98e9136741/172.19.0.11:37901 after 65 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:29.061637","level":"info","event":"25/07/15 18:21:29 INFO Utils: Fetching spark://ee98e9136741:37901/jars/postgresql-42.7.3.jar to /tmp/spark-52c27b48-e9c3-40ec-af45-a99949c3f69c/userFiles-56b6a93b-7c69-465d-9d02-a395265c268f/fetchFileTemp11325071129248131202.tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:29.133003","level":"info","event":"25/07/15 18:21:29 INFO Executor: Adding file:/tmp/spark-52c27b48-e9c3-40ec-af45-a99949c3f69c/userFiles-56b6a93b-7c69-465d-9d02-a395265c268f/postgresql-42.7.3.jar to class loader default","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:29.155061","level":"info","event":"25/07/15 18:21:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35717.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:29.158236","level":"info","event":"25/07/15 18:21:29 INFO NettyBlockTransferService: Server created on ee98e9136741:35717","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:29.158562","level":"info","event":"25/07/15 18:21:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:29.197585","level":"info","event":"25/07/15 18:21:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ee98e9136741, 35717, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:29.224786","level":"info","event":"25/07/15 18:21:29 INFO BlockManagerMasterEndpoint: Registering block manager ee98e9136741:35717 with 434.4 MiB RAM, BlockManagerId(driver, ee98e9136741, 35717, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:29.232460","level":"info","event":"25/07/15 18:21:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ee98e9136741, 35717, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:29.237330","level":"info","event":"25/07/15 18:21:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ee98e9136741, 35717, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:34.301096","level":"info","event":"Reading all JSON files from HDFS path: hdfs://namenode:8020/event_data/*.json","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:34.322220","level":"info","event":"25/07/15 18:21:34 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:34.330537","level":"info","event":"25/07/15 18:21:34 INFO SharedState: Warehouse path is 'file:/tmp/airflowtmpye59y_da/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.018984","level":"info","event":"25/07/15 18:21:37 WARN FileStreamSink: Assume no metadata directory. Error while looking for metadata directory in the path: hdfs://namenode:8020/event_data/*.json.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.019421","level":"info","event":"java.io.FileNotFoundException: File does not exist: hdfs://namenode:8020/event_data/*.json","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.019705","level":"info","event":"\tat org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1832)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.019975","level":"info","event":"\tat org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1825)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.020190","level":"info","event":"\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.020362","level":"info","event":"\tat org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1840)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.020518","level":"info","event":"\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:56)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.020676","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:381)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.020853","level":"info","event":"\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.org$apache$spark$sql$catalyst$analysis$ResolveDataSource$$loadV1BatchSource(ResolveDataSource.scala:143)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.020994","level":"info","event":"\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.$anonfun$applyOrElse$2(ResolveDataSource.scala:61)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.021116","level":"info","event":"\tat scala.Option.getOrElse(Option.scala:201)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.021242","level":"info","event":"\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.applyOrElse(ResolveDataSource.scala:61)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.021370","level":"info","event":"\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.applyOrElse(ResolveDataSource.scala:45)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.021509","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:139)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.021649","level":"info","event":"\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.021774","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:139)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.021929","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:416)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.022074","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:135)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.022202","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:131)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.022342","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:37)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.022462","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:112)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.022583","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:111)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.022706","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:37)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.022823","level":"info","event":"\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.apply(ResolveDataSource.scala:45)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.022963","level":"info","event":"\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.apply(ResolveDataSource.scala:43)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.023083","level":"info","event":"\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:242)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.023204","level":"info","event":"\tat scala.collection.LinearSeqOps.foldLeft(LinearSeq.scala:183)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.023313","level":"info","event":"\tat scala.collection.LinearSeqOps.foldLeft$(LinearSeq.scala:179)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.023418","level":"info","event":"\tat scala.collection.immutable.List.foldLeft(List.scala:79)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.023519","level":"info","event":"\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:239)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.023619","level":"info","event":"\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:231)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.023720","level":"info","event":"\tat scala.collection.immutable.List.foreach(List.scala:334)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.023816","level":"info","event":"\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:231)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.023926","level":"info","event":"\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:290)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.024024","level":"info","event":"\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:286)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.024120","level":"info","event":"\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:234)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.024214","level":"info","event":"\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:286)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.024307","level":"info","event":"\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:249)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.024402","level":"info","event":"\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:201)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.024498","level":"info","event":"\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.024607","level":"info","event":"\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:201)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.024704","level":"info","event":"\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:190)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.024800","level":"info","event":"\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:76)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.024905","level":"info","event":"\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:111)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.025004","level":"info","event":"\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:71)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.025110","level":"info","event":"\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:280)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.025212","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:423)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.025314","level":"info","event":"\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:280)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.025412","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:110)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.025522","level":"info","event":"\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.025622","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:278)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.025727","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.025833","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:278)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.025947","level":"info","event":"\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.026052","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:277)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.026150","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:110)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.026268","level":"info","event":"\tat scala.util.Try$.apply(Try.scala:217)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.026372","level":"info","event":"\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.026471","level":"info","event":"\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.026578","level":"info","event":"\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.026697","level":"info","event":"\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.026816","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:121)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.026953","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:80)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.027060","level":"info","event":"\tat org.apache.spark.sql.classic.Dataset$.$anonfun$ofRows$1(Dataset.scala:115)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.027166","level":"info","event":"\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.027274","level":"info","event":"\tat org.apache.spark.sql.classic.Dataset$.ofRows(Dataset.scala:113)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.027426","level":"info","event":"\tat org.apache.spark.sql.classic.DataFrameReader.load(DataFrameReader.scala:109)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.027553","level":"info","event":"\tat org.apache.spark.sql.classic.DataFrameReader.load(DataFrameReader.scala:58)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.027654","level":"info","event":"\tat org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:296)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.027756","level":"info","event":"\tat org.apache.spark.sql.classic.DataFrameReader.json(DataFrameReader.scala:150)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.027863","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.027965","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.028028","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.028089","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.028159","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.028301","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.028442","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.028560","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.028671","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.028781","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.028925","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.029044","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:37.347641","level":"info","event":"25/07/15 18:21:37 INFO InMemoryFileIndex: It took 195 ms to list leaf files for 11 paths.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:39.204186","level":"info","event":"25/07/15 18:21:39 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:39.209319","level":"info","event":"25/07/15 18:21:39 INFO FileSourceStrategy: Post-Scan Filters: Set()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:40.247780","level":"info","event":"25/07/15 18:21:40 INFO CodeGenerator: Code generated in 483.20852 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:40.295346","level":"info","event":"25/07/15 18:21:40 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:40.350075","level":"info","event":"25/07/15 18:21:40 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 214.6 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:40.444653","level":"info","event":"25/07/15 18:21:40 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 38.7 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:40.460508","level":"info","event":"25/07/15 18:21:40 INFO SparkContext: Created broadcast 0 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:40.554185","level":"info","event":"25/07/15 18:21:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5255292 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:40.828260","level":"info","event":"25/07/15 18:21:40 INFO DAGScheduler: Registering RDD 3 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:40.843124","level":"info","event":"25/07/15 18:21:40 INFO DAGScheduler: Got map stage job 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 5 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:40.847556","level":"info","event":"25/07/15 18:21:40 INFO DAGScheduler: Final stage: ShuffleMapStage 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:40.848568","level":"info","event":"25/07/15 18:21:40 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:40.852130","level":"info","event":"25/07/15 18:21:40 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:40.860416","level":"info","event":"25/07/15 18:21:40 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.069286","level":"info","event":"25/07/15 18:21:41 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 18.4 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.078042","level":"info","event":"25/07/15 18:21:41 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.079736","level":"info","event":"25/07/15 18:21:41 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.128758","level":"info","event":"25/07/15 18:21:41 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.136313","level":"info","event":"25/07/15 18:21:41 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.317849","level":"info","event":"25/07/15 18:21:41 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (ee98e9136741,executor driver, partition 0, ANY, 10598 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.330458","level":"info","event":"25/07/15 18:21:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (ee98e9136741,executor driver, partition 1, ANY, 10598 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.335295","level":"info","event":"25/07/15 18:21:41 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2) (ee98e9136741,executor driver, partition 2, ANY, 10598 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.340723","level":"info","event":"25/07/15 18:21:41 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3) (ee98e9136741,executor driver, partition 3, ANY, 10598 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.341357","level":"info","event":"25/07/15 18:21:41 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4) (ee98e9136741,executor driver, partition 4, ANY, 10598 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.375164","level":"info","event":"25/07/15 18:21:41 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.376901","level":"info","event":"25/07/15 18:21:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.379130","level":"info","event":"25/07/15 18:21:41 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.379411","level":"info","event":"25/07/15 18:21:41 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.384202","level":"info","event":"25/07/15 18:21:41 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.717737","level":"info","event":"25/07/15 18:21:41 INFO CodeGenerator: Code generated in 41.204615 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.747270","level":"info","event":"25/07/15 18:21:41 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.747712","level":"info","event":"25/07/15 18:21:41 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.748052","level":"info","event":"25/07/15 18:21:41 INFO SecurityManager: Changing view acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.749022","level":"info","event":"25/07/15 18:21:41 INFO SecurityManager: Changing modify acls groups to: airflow","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.749189","level":"info","event":"25/07/15 18:21:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.801414","level":"info","event":"25/07/15 18:21:41 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-a973a71e-a4a4-4b58-955d-f2d22ae150e4-c000.json, range: 0-42185, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.801965","level":"info","event":"25/07/15 18:21:41 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-bdf72e3c-9fbc-4556-a7e3-f07e857e14e0-c000.json, range: 0-6948, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.802333","level":"info","event":"25/07/15 18:21:41 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-e98d03af-f16d-41ad-9ccf-5d553106d0f1-c000.json, range: 0-8872, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.806361","level":"info","event":"25/07/15 18:21:41 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-727c03be-2daa-4fce-a4b6-f8ee13e98ba8-c000.json, range: 0-2015, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.824006","level":"info","event":"25/07/15 18:21:41 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-37e7ed6a-9d2d-4c7a-870d-6c2026170aa7-c000.json, range: 0-6408, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:41.855006","level":"info","event":"25/07/15 18:21:41 INFO CodeGenerator: Code generated in 23.860077 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.204168","level":"info","event":"25/07/15 18:21:42 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-fc801e14-7db7-42cc-bd37-3c5feff25190-c000.json, range: 0-1645, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.204568","level":"info","event":"25/07/15 18:21:42 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-d153d04f-2a2b-47bf-86d3-0f12df7b6739-c000.json, range: 0-7022, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.227108","level":"info","event":"25/07/15 18:21:42 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-337a50bf-388c-4838-a801-dfa030827c74-c000.json, range: 0-4712, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.228513","level":"info","event":"25/07/15 18:21:42 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-2c851313-c4cf-46a1-bb85-bc115ff13f17-c000.json, range: 0-6734, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.245189","level":"info","event":"25/07/15 18:21:42 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-fd4d11d5-0735-4806-9242-6d35bbc4fa44-c000.json, range: 0-12762, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.387384","level":"info","event":"25/07/15 18:21:42 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1999 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.390144","level":"info","event":"25/07/15 18:21:42 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1999 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.390412","level":"info","event":"25/07/15 18:21:42 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1999 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.390623","level":"info","event":"25/07/15 18:21:42 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1999 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.390812","level":"info","event":"25/07/15 18:21:42 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1999 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.424604","level":"info","event":"25/07/15 18:21:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1203 ms on ee98e9136741 (executor driver) (1/5)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.438100","level":"info","event":"25/07/15 18:21:42 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1110 ms on ee98e9136741 (executor driver) (2/5)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.438306","level":"info","event":"25/07/15 18:21:42 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 1099 ms on ee98e9136741 (executor driver) (3/5)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.440253","level":"info","event":"25/07/15 18:21:42 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 1104 ms on ee98e9136741 (executor driver) (4/5)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.440807","level":"info","event":"25/07/15 18:21:42 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 1107 ms on ee98e9136741 (executor driver) (5/5)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.456409","level":"info","event":"25/07/15 18:21:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.498765","level":"info","event":"25/07/15 18:21:42 INFO DAGScheduler: ShuffleMapStage 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 1598 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.503343","level":"info","event":"25/07/15 18:21:42 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.510320","level":"info","event":"25/07/15 18:21:42 INFO DAGScheduler: running: HashSet()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.510580","level":"info","event":"25/07/15 18:21:42 INFO DAGScheduler: waiting: HashSet()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.513687","level":"info","event":"25/07/15 18:21:42 INFO DAGScheduler: failed: HashSet()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.681668","level":"info","event":"25/07/15 18:21:42 INFO CodeGenerator: Code generated in 63.170381 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.824107","level":"info","event":"25/07/15 18:21:42 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.837298","level":"info","event":"25/07/15 18:21:42 INFO DAGScheduler: Got job 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.845407","level":"info","event":"25/07/15 18:21:42 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.848198","level":"info","event":"25/07/15 18:21:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.853853","level":"info","event":"25/07/15 18:21:42 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.854181","level":"info","event":"25/07/15 18:21:42 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[6] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.875810","level":"info","event":"25/07/15 18:21:42 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 13.6 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.884573","level":"info","event":"25/07/15 18:21:42 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.891833","level":"info","event":"25/07/15 18:21:42 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.901181","level":"info","event":"25/07/15 18:21:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.901510","level":"info","event":"25/07/15 18:21:42 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.916232","level":"info","event":"25/07/15 18:21:42 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5) (ee98e9136741,executor driver, partition 0, NODE_LOCAL, 9811 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:42.921628","level":"info","event":"25/07/15 18:21:42 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:43.067320","level":"info","event":"25/07/15 18:21:43 INFO ShuffleBlockFetcherIterator: Getting 5 (300.0 B) non-empty blocks including 5 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:43.074152","level":"info","event":"25/07/15 18:21:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 36 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:43.165400","level":"info","event":"25/07/15 18:21:43 INFO CodeGenerator: Code generated in 70.277658 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:43.214998","level":"info","event":"25/07/15 18:21:43 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 3938 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:43.220627","level":"info","event":"25/07/15 18:21:43 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 313 ms on ee98e9136741 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:43.221037","level":"info","event":"25/07/15 18:21:43 INFO TaskSchedulerImpl: Removed TaskSet 2.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:43.235418","level":"info","event":"25/07/15 18:21:43 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 359 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:43.240422","level":"info","event":"25/07/15 18:21:43 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:43.241660","level":"info","event":"25/07/15 18:21:43 INFO TaskSchedulerImpl: Canceling stage 2","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:43.245076","level":"info","event":"25/07/15 18:21:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:43.251911","level":"info","event":"25/07/15 18:21:43 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 431.1388 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:43.288260","level":"info","event":"Total rows in all files: 293","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:45.744478","level":"info","event":"25/07/15 18:21:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(event_type),EqualTo(event_type,search)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:45.747150","level":"info","event":"25/07/15 18:21:45 INFO FileSourceStrategy: Post-Scan Filters: Set(isnotnull(event_type#3), (event_type#3 = search))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:45.784330","level":"info","event":"25/07/15 18:21:45 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.044045","level":"info","event":"25/07/15 18:21:46 INFO CodeGenerator: Code generated in 117.238311 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.055247","level":"info","event":"25/07/15 18:21:46 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 214.6 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.075014","level":"info","event":"25/07/15 18:21:46 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 38.7 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.079137","level":"info","event":"25/07/15 18:21:46 INFO SparkContext: Created broadcast 3 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.092443","level":"info","event":"25/07/15 18:21:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5255292 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.237823","level":"info","event":"25/07/15 18:21:46 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.250304","level":"info","event":"25/07/15 18:21:46 INFO DAGScheduler: Got job 2 (save at NativeMethodAccessorImpl.java:0) with 5 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.250550","level":"info","event":"25/07/15 18:21:46 INFO DAGScheduler: Final stage: ResultStage 3 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.250693","level":"info","event":"25/07/15 18:21:46 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.250848","level":"info","event":"25/07/15 18:21:46 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.251037","level":"info","event":"25/07/15 18:21:46 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[12] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.366045","level":"info","event":"25/07/15 18:21:46 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 45.3 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.371675","level":"info","event":"25/07/15 18:21:46 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 18.3 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.374682","level":"info","event":"25/07/15 18:21:46 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.379126","level":"info","event":"25/07/15 18:21:46 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 3 (MapPartitionsRDD[12] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.379488","level":"info","event":"25/07/15 18:21:46 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.392453","level":"info","event":"25/07/15 18:21:46 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6) (ee98e9136741,executor driver, partition 0, ANY, 10609 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.399422","level":"info","event":"25/07/15 18:21:46 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7) (ee98e9136741,executor driver, partition 1, ANY, 10609 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.400051","level":"info","event":"25/07/15 18:21:46 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8) (ee98e9136741,executor driver, partition 2, ANY, 10609 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.401787","level":"info","event":"25/07/15 18:21:46 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9) (ee98e9136741,executor driver, partition 3, ANY, 10609 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.426148","level":"info","event":"25/07/15 18:21:46 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 10) (ee98e9136741,executor driver, partition 4, ANY, 10609 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.426970","level":"info","event":"25/07/15 18:21:46 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.427560","level":"info","event":"25/07/15 18:21:46 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.428091","level":"info","event":"25/07/15 18:21:46 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.428549","level":"info","event":"25/07/15 18:21:46 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.442019","level":"info","event":"25/07/15 18:21:46 INFO Executor: Running task 4.0 in stage 3.0 (TID 10)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.649630","level":"info","event":"25/07/15 18:21:46 INFO CodeGenerator: Code generated in 97.204752 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.852610","level":"info","event":"25/07/15 18:21:46 INFO CodeGenerator: Code generated in 98.858431 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.853289","level":"info","event":"25/07/15 18:21:46 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-a973a71e-a4a4-4b58-955d-f2d22ae150e4-c000.json, range: 0-42185, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.853852","level":"info","event":"25/07/15 18:21:46 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-37e7ed6a-9d2d-4c7a-870d-6c2026170aa7-c000.json, range: 0-6408, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.854340","level":"info","event":"25/07/15 18:21:46 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-bdf72e3c-9fbc-4556-a7e3-f07e857e14e0-c000.json, range: 0-6948, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.854737","level":"info","event":"25/07/15 18:21:46 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-727c03be-2daa-4fce-a4b6-f8ee13e98ba8-c000.json, range: 0-2015, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:46.855256","level":"info","event":"25/07/15 18:21:46 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-e98d03af-f16d-41ad-9ccf-5d553106d0f1-c000.json, range: 0-8872, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:47.015304","level":"info","event":"25/07/15 18:21:47 INFO CodeGenerator: Code generated in 111.012369 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:47.137632","level":"info","event":"25/07/15 18:21:47 INFO CodeGenerator: Code generated in 29.038415 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:47.879368","level":"info","event":"25/07/15 18:21:47 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-337a50bf-388c-4838-a801-dfa030827c74-c000.json, range: 0-4712, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:47.899145","level":"info","event":"25/07/15 18:21:47 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-fc801e14-7db7-42cc-bd37-3c5feff25190-c000.json, range: 0-1645, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:47.902869","level":"info","event":"25/07/15 18:21:47 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-2c851313-c4cf-46a1-bb85-bc115ff13f17-c000.json, range: 0-6734, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:47.904157","level":"info","event":"25/07/15 18:21:47 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-d153d04f-2a2b-47bf-86d3-0f12df7b6739-c000.json, range: 0-7022, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:47.946371","level":"info","event":"25/07/15 18:21:47 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-fd4d11d5-0735-4806-9242-6d35bbc4fa44-c000.json, range: 0-12762, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:48.112140","level":"info","event":"25/07/15 18:21:48 INFO Executor: Finished task 4.0 in stage 3.0 (TID 10). 1735 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:48.113618","level":"info","event":"25/07/15 18:21:48 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 1692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:48.115631","level":"info","event":"25/07/15 18:21:48 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 1735 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:48.122251","level":"info","event":"25/07/15 18:21:48 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 10) in 1714 ms on ee98e9136741 (executor driver) (1/5)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:48.122567","level":"info","event":"25/07/15 18:21:48 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 1724 ms on ee98e9136741 (executor driver) (2/5)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:48.122797","level":"info","event":"25/07/15 18:21:48 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 1692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:48.124100","level":"info","event":"25/07/15 18:21:48 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 1719 ms on ee98e9136741 (executor driver) (3/5)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:48.124356","level":"info","event":"25/07/15 18:21:48 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 1730 ms on ee98e9136741 (executor driver) (4/5)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:48.194507","level":"info","event":"25/07/15 18:21:48 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 1692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:48.195594","level":"info","event":"25/07/15 18:21:48 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 1809 ms on ee98e9136741 (executor driver) (5/5)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:48.196400","level":"info","event":"25/07/15 18:21:48 INFO TaskSchedulerImpl: Removed TaskSet 3.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:48.196785","level":"info","event":"25/07/15 18:21:48 INFO DAGScheduler: ResultStage 3 (save at NativeMethodAccessorImpl.java:0) finished in 1933 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:48.197186","level":"info","event":"25/07/15 18:21:48 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:48.197342","level":"info","event":"25/07/15 18:21:48 INFO TaskSchedulerImpl: Canceling stage 3","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:48.197487","level":"info","event":"25/07/15 18:21:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:48.199753","level":"info","event":"25/07/15 18:21:48 INFO DAGScheduler: Job 2 finished: save at NativeMethodAccessorImpl.java:0, took 1960.4954 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.664006","level":"info","event":"25/07/15 18:21:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(event_type),EqualTo(event_type,error)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.665994","level":"info","event":"25/07/15 18:21:49 INFO FileSourceStrategy: Post-Scan Filters: Set(isnotnull(event_type#3), (event_type#3 = error))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.730115","level":"info","event":"25/07/15 18:21:49 INFO CodeGenerator: Code generated in 32.993796 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.741047","level":"info","event":"25/07/15 18:21:49 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 214.6 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.762131","level":"info","event":"25/07/15 18:21:49 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 38.7 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.765252","level":"info","event":"25/07/15 18:21:49 INFO SparkContext: Created broadcast 5 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.775427","level":"info","event":"25/07/15 18:21:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5255292 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.839955","level":"info","event":"25/07/15 18:21:49 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.851184","level":"info","event":"25/07/15 18:21:49 INFO DAGScheduler: Got job 3 (save at NativeMethodAccessorImpl.java:0) with 5 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.851517","level":"info","event":"25/07/15 18:21:49 INFO DAGScheduler: Final stage: ResultStage 4 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.851743","level":"info","event":"25/07/15 18:21:49 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.851951","level":"info","event":"25/07/15 18:21:49 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.852127","level":"info","event":"25/07/15 18:21:49 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[18] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.865050","level":"info","event":"25/07/15 18:21:49 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 39.9 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.867246","level":"info","event":"25/07/15 18:21:49 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.871071","level":"info","event":"25/07/15 18:21:49 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.874289","level":"info","event":"25/07/15 18:21:49 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.874767","level":"info","event":"25/07/15 18:21:49 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.881155","level":"info","event":"25/07/15 18:21:49 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 11) (ee98e9136741,executor driver, partition 0, ANY, 10609 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.885421","level":"info","event":"25/07/15 18:21:49 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 12) (ee98e9136741,executor driver, partition 1, ANY, 10609 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.887128","level":"info","event":"25/07/15 18:21:49 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 13) (ee98e9136741,executor driver, partition 2, ANY, 10609 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.889233","level":"info","event":"25/07/15 18:21:49 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 14) (ee98e9136741,executor driver, partition 3, ANY, 10609 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.890190","level":"info","event":"25/07/15 18:21:49 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 15) (ee98e9136741,executor driver, partition 4, ANY, 10609 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.895629","level":"info","event":"25/07/15 18:21:49 INFO Executor: Running task 1.0 in stage 4.0 (TID 12)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.896105","level":"info","event":"25/07/15 18:21:49 INFO Executor: Running task 0.0 in stage 4.0 (TID 11)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.896414","level":"info","event":"25/07/15 18:21:49 INFO Executor: Running task 2.0 in stage 4.0 (TID 13)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.896652","level":"info","event":"25/07/15 18:21:49 INFO Executor: Running task 3.0 in stage 4.0 (TID 14)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.896904","level":"info","event":"25/07/15 18:21:49 INFO Executor: Running task 4.0 in stage 4.0 (TID 15)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:49.939684","level":"info","event":"25/07/15 18:21:49 INFO CodeGenerator: Code generated in 25.204227 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.001827","level":"info","event":"25/07/15 18:21:50 INFO CodeGenerator: Code generated in 46.910679 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.008999","level":"info","event":"25/07/15 18:21:50 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-bdf72e3c-9fbc-4556-a7e3-f07e857e14e0-c000.json, range: 0-6948, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.015397","level":"info","event":"25/07/15 18:21:50 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-727c03be-2daa-4fce-a4b6-f8ee13e98ba8-c000.json, range: 0-2015, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.019660","level":"info","event":"25/07/15 18:21:50 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-37e7ed6a-9d2d-4c7a-870d-6c2026170aa7-c000.json, range: 0-6408, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.020290","level":"info","event":"25/07/15 18:21:50 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-a973a71e-a4a4-4b58-955d-f2d22ae150e4-c000.json, range: 0-42185, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.020510","level":"info","event":"25/07/15 18:21:50 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-e98d03af-f16d-41ad-9ccf-5d553106d0f1-c000.json, range: 0-8872, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.055476","level":"info","event":"25/07/15 18:21:50 INFO CodeGenerator: Code generated in 28.569143 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.098099","level":"info","event":"25/07/15 18:21:50 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-fc801e14-7db7-42cc-bd37-3c5feff25190-c000.json, range: 0-1645, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.669006","level":"info","event":"25/07/15 18:21:50 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-2c851313-c4cf-46a1-bb85-bc115ff13f17-c000.json, range: 0-6734, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.689683","level":"info","event":"25/07/15 18:21:50 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-337a50bf-388c-4838-a801-dfa030827c74-c000.json, range: 0-4712, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.693182","level":"info","event":"25/07/15 18:21:50 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-d153d04f-2a2b-47bf-86d3-0f12df7b6739-c000.json, range: 0-7022, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.703296","level":"info","event":"25/07/15 18:21:50 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-fd4d11d5-0735-4806-9242-6d35bbc4fa44-c000.json, range: 0-12762, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.879063","level":"info","event":"25/07/15 18:21:50 INFO Executor: Finished task 2.0 in stage 4.0 (TID 13). 1649 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.881937","level":"info","event":"25/07/15 18:21:50 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 13) in 996 ms on ee98e9136741 (executor driver) (1/5)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.887605","level":"info","event":"25/07/15 18:21:50 INFO Executor: Finished task 4.0 in stage 4.0 (TID 15). 1649 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.890909","level":"info","event":"25/07/15 18:21:50 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 15) in 1002 ms on ee98e9136741 (executor driver) (2/5)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.901195","level":"info","event":"25/07/15 18:21:50 INFO Executor: Finished task 3.0 in stage 4.0 (TID 14). 1649 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.903179","level":"info","event":"25/07/15 18:21:50 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 14) in 1016 ms on ee98e9136741 (executor driver) (3/5)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.903695","level":"info","event":"25/07/15 18:21:50 INFO Executor: Finished task 1.0 in stage 4.0 (TID 12). 1649 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.905157","level":"info","event":"25/07/15 18:21:50 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 12) in 1023 ms on ee98e9136741 (executor driver) (4/5)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.920463","level":"info","event":"25/07/15 18:21:50 INFO Executor: Finished task 0.0 in stage 4.0 (TID 11). 1692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.925162","level":"info","event":"25/07/15 18:21:50 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 11) in 1045 ms on ee98e9136741 (executor driver) (5/5)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.926069","level":"info","event":"25/07/15 18:21:50 INFO TaskSchedulerImpl: Removed TaskSet 4.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.926595","level":"info","event":"25/07/15 18:21:50 INFO DAGScheduler: ResultStage 4 (save at NativeMethodAccessorImpl.java:0) finished in 1072 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.927018","level":"info","event":"25/07/15 18:21:50 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.927391","level":"info","event":"25/07/15 18:21:50 INFO TaskSchedulerImpl: Canceling stage 4","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.927590","level":"info","event":"25/07/15 18:21:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:50.930072","level":"info","event":"25/07/15 18:21:50 INFO DAGScheduler: Job 3 finished: save at NativeMethodAccessorImpl.java:0, took 1089.120018 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.444044","level":"info","event":"25/07/15 18:21:52 INFO FileSourceStrategy: Pushed Filters: IsNotNull(event_type),EqualTo(event_type,order_complete)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.444338","level":"info","event":"25/07/15 18:21:52 INFO FileSourceStrategy: Post-Scan Filters: Set(isnotnull(event_type#3), (event_type#3 = order_complete))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.547690","level":"info","event":"25/07/15 18:21:52 INFO CodeGenerator: Code generated in 52.674572 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.553262","level":"info","event":"25/07/15 18:21:52 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 214.6 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.606711","level":"info","event":"25/07/15 18:21:52 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 38.7 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.610498","level":"info","event":"25/07/15 18:21:52 INFO SparkContext: Created broadcast 7 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.619612","level":"info","event":"25/07/15 18:21:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5255292 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.666759","level":"info","event":"25/07/15 18:21:52 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.669454","level":"info","event":"25/07/15 18:21:52 INFO DAGScheduler: Got job 4 (save at NativeMethodAccessorImpl.java:0) with 5 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.675969","level":"info","event":"25/07/15 18:21:52 INFO DAGScheduler: Final stage: ResultStage 5 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.676334","level":"info","event":"25/07/15 18:21:52 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.676607","level":"info","event":"25/07/15 18:21:52 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.683461","level":"info","event":"25/07/15 18:21:52 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[24] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.770591","level":"info","event":"25/07/15 18:21:52 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 53.1 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.773490","level":"info","event":"25/07/15 18:21:52 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.789654","level":"info","event":"25/07/15 18:21:52 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1676","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.806682","level":"info","event":"25/07/15 18:21:52 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 5 (MapPartitionsRDD[24] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.822090","level":"info","event":"25/07/15 18:21:52 INFO TaskSchedulerImpl: Adding task set 5.0 with 5 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.822413","level":"info","event":"25/07/15 18:21:52 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 16) (ee98e9136741,executor driver, partition 0, ANY, 10609 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.822661","level":"info","event":"25/07/15 18:21:52 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 17) (ee98e9136741,executor driver, partition 1, ANY, 10609 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.822879","level":"info","event":"25/07/15 18:21:52 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 18) (ee98e9136741,executor driver, partition 2, ANY, 10609 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.823117","level":"info","event":"25/07/15 18:21:52 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 19) (ee98e9136741,executor driver, partition 3, ANY, 10609 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.823295","level":"info","event":"25/07/15 18:21:52 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 20) (ee98e9136741,executor driver, partition 4, ANY, 10609 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.823463","level":"info","event":"25/07/15 18:21:52 INFO Executor: Running task 4.0 in stage 5.0 (TID 20)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.823616","level":"info","event":"25/07/15 18:21:52 INFO Executor: Running task 1.0 in stage 5.0 (TID 17)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.823760","level":"info","event":"25/07/15 18:21:52 INFO Executor: Running task 2.0 in stage 5.0 (TID 18)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.823911","level":"info","event":"25/07/15 18:21:52 INFO Executor: Running task 0.0 in stage 5.0 (TID 16)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.824055","level":"info","event":"25/07/15 18:21:52 INFO Executor: Running task 3.0 in stage 5.0 (TID 19)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.874730","level":"info","event":"25/07/15 18:21:52 INFO CodeGenerator: Code generated in 47.917811 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.946863","level":"info","event":"25/07/15 18:21:52 INFO CodeGenerator: Code generated in 54.572401 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.954151","level":"info","event":"25/07/15 18:21:52 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-a973a71e-a4a4-4b58-955d-f2d22ae150e4-c000.json, range: 0-42185, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.954444","level":"info","event":"25/07/15 18:21:52 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-e98d03af-f16d-41ad-9ccf-5d553106d0f1-c000.json, range: 0-8872, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.954659","level":"info","event":"25/07/15 18:21:52 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-727c03be-2daa-4fce-a4b6-f8ee13e98ba8-c000.json, range: 0-2015, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.954850","level":"info","event":"25/07/15 18:21:52 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-37e7ed6a-9d2d-4c7a-870d-6c2026170aa7-c000.json, range: 0-6408, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:52.955041","level":"info","event":"25/07/15 18:21:52 INFO FileScanRDD: Reading File path: hdfs://namenode:8020/event_data/part-00000-bdf72e3c-9fbc-4556-a7e3-f07e857e14e0-c000.json, range: 0-6948, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.381481","level":"info","event":"25/07/15 18:21:53 ERROR Executor: Exception in task 4.0 in stage 5.0 (TID 20)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.382908","level":"info","event":"org.postgresql.util.PSQLException: FATAL: Max client connections reached","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.383237","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.383495","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2837)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.383735","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:175)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.383974","level":"info","event":"\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:317)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.384177","level":"info","event":"\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.384361","level":"info","event":"\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:273)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.384515","level":"info","event":"\tat org.postgresql.Driver.makeConnection(Driver.java:446)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.384658","level":"info","event":"\tat org.postgresql.Driver.connect(Driver.java:298)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.384842","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:50)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.385033","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.385198","level":"info","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:235)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.385348","level":"info","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:231)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.385495","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:777)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.385639","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:995)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.385780","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:994)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.388245","level":"info","event":"\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.388548","level":"info","event":"\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.388746","level":"info","event":"\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.388944","level":"info","event":"\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.389108","level":"info","event":"\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.389256","level":"info","event":"\tat org.apache.spark.scheduler.Task.run(Task.scala:147)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.389390","level":"info","event":"\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.389516","level":"info","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.389638","level":"info","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.389759","level":"info","event":"\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.389879","level":"info","event":"\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.390012","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.390128","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.390231","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.390360","level":"info","event":"25/07/15 18:21:53 ERROR Executor: Exception in task 1.0 in stage 5.0 (TID 17)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.390482","level":"info","event":"org.postgresql.util.PSQLException: FATAL: Max client connections reached","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.390607","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.390728","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2837)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.390843","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:175)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.390970","level":"info","event":"\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:317)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.391083","level":"info","event":"\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.391189","level":"info","event":"\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:273)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.391303","level":"info","event":"\tat org.postgresql.Driver.makeConnection(Driver.java:446)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.392438","level":"info","event":"\tat org.postgresql.Driver.connect(Driver.java:298)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.392604","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:50)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.392747","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.392869","level":"info","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:235)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.393002","level":"info","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:231)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.393113","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:777)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.393226","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:995)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.393327","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:994)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.393437","level":"info","event":"\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.393538","level":"info","event":"\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.393647","level":"info","event":"\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.393744","level":"info","event":"\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.393849","level":"info","event":"\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.394050","level":"info","event":"\tat org.apache.spark.scheduler.Task.run(Task.scala:147)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.394159","level":"info","event":"\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.397544","level":"info","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.402324","level":"info","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.402710","level":"info","event":"\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.402973","level":"info","event":"\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.403231","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.403458","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.403660","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.403844","level":"info","event":"25/07/15 18:21:53 ERROR Executor: Exception in task 3.0 in stage 5.0 (TID 19)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.404015","level":"info","event":"org.postgresql.util.PSQLException: FATAL: Max client connections reached","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.404168","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.407851","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2837)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.408078","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:175)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.408251","level":"info","event":"\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:317)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.408407","level":"info","event":"\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.410237","level":"info","event":"\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:273)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.410446","level":"info","event":"\tat org.postgresql.Driver.makeConnection(Driver.java:446)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.410658","level":"info","event":"\tat org.postgresql.Driver.connect(Driver.java:298)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.410973","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:50)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.411196","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.411345","level":"info","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:235)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.411495","level":"info","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:231)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.411643","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:777)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.411778","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:995)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.411952","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:994)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.412091","level":"info","event":"\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.412654","level":"info","event":"\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.412962","level":"info","event":"\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.413183","level":"info","event":"\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.413332","level":"info","event":"\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.413474","level":"info","event":"\tat org.apache.spark.scheduler.Task.run(Task.scala:147)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.413610","level":"info","event":"\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.413784","level":"info","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.413961","level":"info","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.414121","level":"info","event":"\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.414277","level":"info","event":"\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.414530","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.414704","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.414857","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.415028","level":"info","event":"25/07/15 18:21:53 ERROR Executor: Exception in task 2.0 in stage 5.0 (TID 18)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.415175","level":"info","event":"org.postgresql.util.PSQLException: FATAL: Max client connections reached","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.415316","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.415440","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2837)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.415558","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:175)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.415673","level":"info","event":"\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:317)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.415786","level":"info","event":"\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.415910","level":"info","event":"\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:273)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.416027","level":"info","event":"\tat org.postgresql.Driver.makeConnection(Driver.java:446)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.416143","level":"info","event":"\tat org.postgresql.Driver.connect(Driver.java:298)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.416256","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:50)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.416371","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.416486","level":"info","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:235)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.416662","level":"info","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:231)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.416782","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:777)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.416910","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:995)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.417031","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:994)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.417146","level":"info","event":"\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.417261","level":"info","event":"\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.417375","level":"info","event":"\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.417490","level":"info","event":"\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.417608","level":"info","event":"\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.417720","level":"info","event":"\tat org.apache.spark.scheduler.Task.run(Task.scala:147)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.417832","level":"info","event":"\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.417957","level":"info","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.418071","level":"info","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.418193","level":"info","event":"\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.418314","level":"info","event":"\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.418429","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.418547","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.418719","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.418841","level":"info","event":"25/07/15 18:21:53 ERROR Executor: Exception in task 0.0 in stage 5.0 (TID 16)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.418990","level":"info","event":"org.postgresql.util.PSQLException: FATAL: Max client connections reached","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.419132","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.419298","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2837)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.419459","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:175)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.419612","level":"info","event":"\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:317)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.419766","level":"info","event":"\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.419933","level":"info","event":"\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:273)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.420084","level":"info","event":"\tat org.postgresql.Driver.makeConnection(Driver.java:446)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.420245","level":"info","event":"\tat org.postgresql.Driver.connect(Driver.java:298)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.420395","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:50)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.420526","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.420751","level":"info","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:235)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.420939","level":"info","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:231)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.421108","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:777)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.421245","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:995)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.421371","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:994)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.421499","level":"info","event":"\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.421655","level":"info","event":"\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.421804","level":"info","event":"\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.421962","level":"info","event":"\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.422100","level":"info","event":"\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.422240","level":"info","event":"\tat org.apache.spark.scheduler.Task.run(Task.scala:147)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.422377","level":"info","event":"\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.422517","level":"info","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.422657","level":"info","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.422772","level":"info","event":"\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.424518","level":"info","event":"\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.424835","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.425667","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.426042","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.433755","level":"info","event":"25/07/15 18:21:53 WARN TaskSetManager: Lost task 0.0 in stage 5.0 (TID 16) (ee98e9136741 executor driver): org.postgresql.util.PSQLException: FATAL: Max client connections reached","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.434030","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.434229","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2837)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.434400","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:175)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.434562","level":"info","event":"\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:317)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.434714","level":"info","event":"\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.434849","level":"info","event":"\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:273)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.435001","level":"info","event":"\tat org.postgresql.Driver.makeConnection(Driver.java:446)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.435137","level":"info","event":"\tat org.postgresql.Driver.connect(Driver.java:298)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.437400","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:50)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.437840","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.438268","level":"info","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:235)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.438610","level":"info","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:231)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.438832","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:777)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.439071","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:995)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.439281","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:994)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.440501","level":"info","event":"\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.440871","level":"info","event":"\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.441106","level":"info","event":"\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.441287","level":"info","event":"\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.441455","level":"info","event":"\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.441619","level":"info","event":"\tat org.apache.spark.scheduler.Task.run(Task.scala:147)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.441786","level":"info","event":"\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.441953","level":"info","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.442108","level":"info","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.442263","level":"info","event":"\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.442409","level":"info","event":"\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.442561","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.442699","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.442829","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.442979","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.443127","level":"info","event":"25/07/15 18:21:53 ERROR TaskSetManager: Task 0 in stage 5.0 failed 1 times; aborting job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.445774","level":"info","event":"25/07/15 18:21:53 INFO TaskSetManager: Lost task 4.0 in stage 5.0 (TID 20) on ee98e9136741, executor driver: org.postgresql.util.PSQLException (FATAL: Max client connections reached) [duplicate 1]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.446613","level":"info","event":"25/07/15 18:21:53 INFO TaskSetManager: Lost task 1.0 in stage 5.0 (TID 17) on ee98e9136741, executor driver: org.postgresql.util.PSQLException (FATAL: Max client connections reached) [duplicate 2]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.453992","level":"info","event":"25/07/15 18:21:53 INFO TaskSetManager: Lost task 2.0 in stage 5.0 (TID 18) on ee98e9136741, executor driver: org.postgresql.util.PSQLException (FATAL: Max client connections reached) [duplicate 3]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.454300","level":"info","event":"25/07/15 18:21:53 INFO TaskSchedulerImpl: Removed TaskSet 5.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.455375","level":"info","event":"25/07/15 18:21:53 INFO TaskSetManager: Lost task 3.0 in stage 5.0 (TID 19) on ee98e9136741, executor driver: org.postgresql.util.PSQLException (FATAL: Max client connections reached) [duplicate 4]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.455632","level":"info","event":"25/07/15 18:21:53 INFO TaskSchedulerImpl: Removed TaskSet 5.0 whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.455816","level":"info","event":"25/07/15 18:21:53 INFO TaskSchedulerImpl: Canceling stage 5","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.455996","level":"info","event":"25/07/15 18:21:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 16) (ee98e9136741 executor driver): org.postgresql.util.PSQLException: FATAL: Max client connections reached","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.456203","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.456352","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2837)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.456491","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:175)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.456634","level":"info","event":"\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:317)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.456772","level":"info","event":"\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.456917","level":"info","event":"\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:273)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.457048","level":"info","event":"\tat org.postgresql.Driver.makeConnection(Driver.java:446)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.457172","level":"info","event":"\tat org.postgresql.Driver.connect(Driver.java:298)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.457294","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:50)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.457414","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.457541","level":"info","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:235)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.457655","level":"info","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:231)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.457765","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:777)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.457877","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:995)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.458002","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:994)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.458113","level":"info","event":"\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.458227","level":"info","event":"\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.458338","level":"info","event":"\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.458523","level":"info","event":"\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.458638","level":"info","event":"\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.458749","level":"info","event":"\tat org.apache.spark.scheduler.Task.run(Task.scala:147)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.458860","level":"info","event":"\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.458983","level":"info","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.459093","level":"info","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.459205","level":"info","event":"\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.459316","level":"info","event":"\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.459424","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.459530","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.459636","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.459745","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.459856","level":"info","event":"Driver stacktrace:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.459987","level":"info","event":"25/07/15 18:21:53 INFO DAGScheduler: ResultStage 5 (save at NativeMethodAccessorImpl.java:0) failed in 768 ms due to Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 16) (ee98e9136741 executor driver): org.postgresql.util.PSQLException: FATAL: Max client connections reached","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.460106","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.460213","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2837)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.460320","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:175)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.460428","level":"info","event":"\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:317)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.460537","level":"info","event":"\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.460644","level":"info","event":"\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:273)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.460749","level":"info","event":"\tat org.postgresql.Driver.makeConnection(Driver.java:446)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.460855","level":"info","event":"\tat org.postgresql.Driver.connect(Driver.java:298)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.460977","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:50)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.461088","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.461194","level":"info","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:235)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.461301","level":"info","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:231)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.461404","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:777)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.461508","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:995)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.461629","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:994)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.461739","level":"info","event":"\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.461848","level":"info","event":"\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.461973","level":"info","event":"\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.462086","level":"info","event":"\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.462197","level":"info","event":"\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.462307","level":"info","event":"\tat org.apache.spark.scheduler.Task.run(Task.scala:147)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.462416","level":"info","event":"\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.462525","level":"info","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.462646","level":"info","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.462768","level":"info","event":"\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.462905","level":"info","event":"\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.463025","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.463200","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.463320","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.463431","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.463816","level":"info","event":"Driver stacktrace:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.464022","level":"info","event":"25/07/15 18:21:53 INFO DAGScheduler: Job 4 failed: save at NativeMethodAccessorImpl.java:0, took 792.612049 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.712330","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.712621","level":"info","event":"  File \"/opt/airflow/scripts/spark_jop/batch_jop.py\", line 178, in <module>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.713496","level":"info","event":"    .save()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.713709","level":"info","event":"     ^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.713923","level":"info","event":"  File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/readwriter.py\", line 1743, in save","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.714111","level":"info","event":"  File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/py4j-0.10.9.9-src.zip/py4j/java_gateway.py\", line 1362, in __call__","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.714278","level":"info","event":"  File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py\", line 282, in deco","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.714433","level":"info","event":"  File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/py4j-0.10.9.9-src.zip/py4j/protocol.py\", line 327, in get_return_value","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.756735","level":"info","event":"py4j.protocol.Py4JJavaError: An error occurred while calling o229.save.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.757076","level":"info","event":": org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 16) (ee98e9136741 executor driver): org.postgresql.util.PSQLException: FATAL: Max client connections reached","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.757262","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.757411","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2837)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.757552","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:175)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.757689","level":"info","event":"\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:317)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.757820","level":"info","event":"\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.757968","level":"info","event":"\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:273)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.758109","level":"info","event":"\tat org.postgresql.Driver.makeConnection(Driver.java:446)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.758255","level":"info","event":"\tat org.postgresql.Driver.connect(Driver.java:298)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.758394","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:50)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.758540","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.758685","level":"info","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:235)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.758828","level":"info","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:231)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.758985","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:777)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.759123","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:995)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.759258","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:994)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.759400","level":"info","event":"\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.759541","level":"info","event":"\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.759679","level":"info","event":"\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.759820","level":"info","event":"\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.759998","level":"info","event":"\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.760142","level":"info","event":"\tat org.apache.spark.scheduler.Task.run(Task.scala:147)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.760282","level":"info","event":"\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.760421","level":"info","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.760558","level":"info","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.760695","level":"info","event":"\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.760829","level":"info","event":"\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.760984","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.761124","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.761263","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.761398","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.761537","level":"info","event":"Driver stacktrace:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.761677","level":"info","event":"\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.761806","level":"info","event":"\tat scala.Option.getOrElse(Option.scala:201)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.761945","level":"info","event":"\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.762078","level":"info","event":"\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.762219","level":"info","event":"\tat scala.collection.immutable.List.foreach(List.scala:334)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.762359","level":"info","event":"\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.762511","level":"info","event":"\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.762656","level":"info","event":"\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.762803","level":"info","event":"\tat scala.Option.foreach(Option.scala:437)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.762969","level":"info","event":"\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.763115","level":"info","event":"\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.763263","level":"info","event":"\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.763404","level":"info","event":"\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.763542","level":"info","event":"\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.763681","level":"info","event":"\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.763819","level":"info","event":"\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.763984","level":"info","event":"\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.764124","level":"info","event":"\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.764376","level":"info","event":"\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.764521","level":"info","event":"\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.764664","level":"info","event":"\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.764818","level":"info","event":"\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.764972","level":"info","event":"\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.765111","level":"info","event":"\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1045)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.765249","level":"info","event":"\tat org.apache.spark.sql.classic.Dataset.$anonfun$foreachPartition$1(Dataset.scala:1474)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.765384","level":"info","event":"\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.765525","level":"info","event":"\tat org.apache.spark.sql.classic.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:2221)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.765665","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$8(SQLExecution.scala:162)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.765818","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:268)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.765983","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$7(SQLExecution.scala:124)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.766132","level":"info","event":"\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.766280","level":"info","event":"\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.766427","level":"info","event":"\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:106)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.766574","level":"info","event":"\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.766721","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$6(SQLExecution.scala:124)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.766870","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:291)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.770430","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:123)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.770622","level":"info","event":"\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.770785","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.770976","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:233)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.771130","level":"info","event":"\tat org.apache.spark.sql.classic.Dataset.withNewRDDExecutionId(Dataset.scala:2219)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.771284","level":"info","event":"\tat org.apache.spark.sql.classic.Dataset.foreachPartition(Dataset.scala:1474)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.771438","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:994)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.771589","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:71)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.771744","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:55)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.771928","level":"info","event":"\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:79)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.772079","level":"info","event":"\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.772230","level":"info","event":"\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:88)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.772379","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:155)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.772530","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$8(SQLExecution.scala:162)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.772680","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:268)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.772827","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$7(SQLExecution.scala:124)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.772990","level":"info","event":"\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.773766","level":"info","event":"\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.774110","level":"info","event":"\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:106)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.774328","level":"info","event":"\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.774519","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$6(SQLExecution.scala:124)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.774703","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:291)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.774866","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:123)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.775112","level":"info","event":"\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.775271","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.775402","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:233)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.775523","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:155)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.775650","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.775784","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:154)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.775939","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$3.applyOrElse(QueryExecution.scala:169)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.776087","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$3.applyOrElse(QueryExecution.scala:164)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.776221","level":"info","event":"\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:470)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.776358","level":"info","event":"\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.776477","level":"info","event":"\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:470)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.776580","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:37)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.776665","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:360)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.776740","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:356)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.776813","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:37)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.776884","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:37)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.777009","level":"info","event":"\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:446)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.777139","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:164)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.777271","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:126)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.777393","level":"info","event":"\tat scala.util.Try$.apply(Try.scala:217)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.777512","level":"info","event":"\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.777661","level":"info","event":"\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1439)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.777768","level":"info","event":"\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.777860","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:131)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.777971","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:192)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.778048","level":"info","event":"\tat org.apache.spark.sql.classic.DataFrameWriter.runCommand(DataFrameWriter.scala:622)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.778121","level":"info","event":"\tat org.apache.spark.sql.classic.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:273)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.778193","level":"info","event":"\tat org.apache.spark.sql.classic.DataFrameWriter.saveInternal(DataFrameWriter.scala:241)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.778278","level":"info","event":"\tat org.apache.spark.sql.classic.DataFrameWriter.save(DataFrameWriter.scala:126)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.778404","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.778539","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.778672","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.778817","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.778951","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.779034","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.779109","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.779183","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.779254","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.779324","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.779395","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.779470","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.779544","level":"info","event":"\tSuppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.779615","level":"info","event":"\t\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.779686","level":"info","event":"\t\tat scala.Option.getOrElse(Option.scala:201)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.779771","level":"info","event":"\t\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.779849","level":"info","event":"\t\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.779944","level":"info","event":"\t\tat scala.collection.immutable.List.foreach(List.scala:334)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.780019","level":"info","event":"\t\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.780125","level":"info","event":"\t\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.780343","level":"info","event":"\t\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.780475","level":"info","event":"\t\tat scala.Option.foreach(Option.scala:437)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.780603","level":"info","event":"\t\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.780718","level":"info","event":"\t\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.780839","level":"info","event":"\t\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.780975","level":"info","event":"\t\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.781081","level":"info","event":"\t\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.783724","level":"info","event":"\t\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.783923","level":"info","event":"\t\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.784075","level":"info","event":"\t\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.784207","level":"info","event":"\t\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.784323","level":"info","event":"\t\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.784428","level":"info","event":"\t\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.784535","level":"info","event":"\t\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.784637","level":"info","event":"\t\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.784740","level":"info","event":"\t\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.784844","level":"info","event":"\t\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1045)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.784963","level":"info","event":"\t\tat org.apache.spark.sql.classic.Dataset.$anonfun$foreachPartition$1(Dataset.scala:1474)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.785072","level":"info","event":"\t\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.785178","level":"info","event":"\t\tat org.apache.spark.sql.classic.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:2221)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.785295","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$8(SQLExecution.scala:162)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.785422","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:268)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.785628","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$7(SQLExecution.scala:124)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.785763","level":"info","event":"\t\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.785907","level":"info","event":"\t\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.786042","level":"info","event":"\t\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:106)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.786172","level":"info","event":"\t\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.786306","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$6(SQLExecution.scala:124)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.786437","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:291)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.786564","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:123)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.786687","level":"info","event":"\t\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.786809","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.786949","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:233)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.787070","level":"info","event":"\t\tat org.apache.spark.sql.classic.Dataset.withNewRDDExecutionId(Dataset.scala:2219)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.787188","level":"info","event":"\t\tat org.apache.spark.sql.classic.Dataset.foreachPartition(Dataset.scala:1474)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.787306","level":"info","event":"\t\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:994)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.787420","level":"info","event":"\t\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:71)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.787532","level":"info","event":"\t\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:55)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.787705","level":"info","event":"\t\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:79)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.787823","level":"info","event":"\t\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.787962","level":"info","event":"\t\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:88)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.788086","level":"info","event":"\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:155)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.788202","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$8(SQLExecution.scala:162)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.788320","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:268)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.788440","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$7(SQLExecution.scala:124)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.788561","level":"info","event":"\t\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.788687","level":"info","event":"\t\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.788808","level":"info","event":"\t\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:106)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.788940","level":"info","event":"\t\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.789059","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$6(SQLExecution.scala:124)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.790051","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:291)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.790282","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:123)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.790447","level":"info","event":"\t\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.790629","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.790791","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:233)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.790954","level":"info","event":"\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:155)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.791097","level":"info","event":"\t\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.791233","level":"info","event":"\t\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:154)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.791362","level":"info","event":"\t\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$3.applyOrElse(QueryExecution.scala:169)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.791494","level":"info","event":"\t\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$3.applyOrElse(QueryExecution.scala:164)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.791628","level":"info","event":"\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:470)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.791814","level":"info","event":"\t\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.791960","level":"info","event":"\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:470)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.792167","level":"info","event":"\t\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:37)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.792299","level":"info","event":"\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:360)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.792422","level":"info","event":"\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:356)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.792544","level":"info","event":"\t\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:37)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.792663","level":"info","event":"\t\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:37)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.792780","level":"info","event":"\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:446)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.792908","level":"info","event":"\t\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:164)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.793030","level":"info","event":"\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:126)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.793148","level":"info","event":"\t\tat scala.util.Try$.apply(Try.scala:217)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.793266","level":"info","event":"\t\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.793383","level":"info","event":"\t\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.793501","level":"info","event":"\t\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.793621","level":"info","event":"\t\t... 19 more","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.793738","level":"info","event":"Caused by: org.postgresql.util.PSQLException: FATAL: Max client connections reached","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.793856","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.793995","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2837)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.794115","level":"info","event":"\tat org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:175)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.794297","level":"info","event":"\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:317)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.794426","level":"info","event":"\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.794553","level":"info","event":"\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:273)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.794676","level":"info","event":"\tat org.postgresql.Driver.makeConnection(Driver.java:446)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.794799","level":"info","event":"\tat org.postgresql.Driver.connect(Driver.java:298)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.794943","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:50)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.795075","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.795199","level":"info","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:235)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.795322","level":"info","event":"\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:231)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.795439","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:777)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.795556","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:995)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.795673","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:994)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.795818","level":"info","event":"\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.795950","level":"info","event":"\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1047)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.796070","level":"info","event":"\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.796188","level":"info","event":"\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.796357","level":"info","event":"\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.796483","level":"info","event":"\tat org.apache.spark.scheduler.Task.run(Task.scala:147)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.796600","level":"info","event":"\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.796716","level":"info","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.796832","level":"info","event":"\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.796969","level":"info","event":"\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.797097","level":"info","event":"\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.797229","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.797355","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.797486","level":"info","event":"\t... 1 more","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:53.797610","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:54.192361","level":"info","event":"25/07/15 18:21:54 INFO SparkContext: Invoking stop() from shutdown hook","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:54.198214","level":"info","event":"25/07/15 18:21:54 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:54.234123","level":"info","event":"25/07/15 18:21:54 INFO SparkUI: Stopped Spark web UI at http://ee98e9136741:4041","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:54.273402","level":"info","event":"25/07/15 18:21:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:54.303974","level":"info","event":"25/07/15 18:21:54 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:54.305193","level":"info","event":"25/07/15 18:21:54 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:54.310562","level":"info","event":"25/07/15 18:21:54 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:54.315228","level":"info","event":"25/07/15 18:21:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:54.334808","level":"info","event":"25/07/15 18:21:54 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:54.335591","level":"info","event":"25/07/15 18:21:54 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:54.336811","level":"info","event":"25/07/15 18:21:54 INFO ShutdownHookManager: Deleting directory /tmp/airflowtmpye59y_da/artifacts/spark-f58d5f30-6dc9-4c61-9973-5b32aac4cc50","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:54.343018","level":"info","event":"25/07/15 18:21:54 INFO ShutdownHookManager: Deleting directory /tmp/spark-7694c84c-5c7d-498d-9e70-c65f5e80f93f","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:54.351565","level":"info","event":"25/07/15 18:21:54 INFO ShutdownHookManager: Deleting directory /tmp/spark-52c27b48-e9c3-40ec-af45-a99949c3f69c","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:54.358416","level":"info","event":"25/07/15 18:21:54 INFO ShutdownHookManager: Deleting directory /tmp/spark-52c27b48-e9c3-40ec-af45-a99949c3f69c/pyspark-3aff813f-644a-43a5-922c-69aa2483d110","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:54.496624","level":"info","event":"Command exited with return code 1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T18:21:54.497701","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Bash command failed. The command returned a non-zero exit code 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":825,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1088,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":408,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/bash.py","lineno":233,"name":"execute"}]}]}
